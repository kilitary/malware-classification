#!/usr/bin/env python2
import shutil
import sys

import time

import pefile
import os
import hashlib
import array
import math
from overrides import len3, sum3
import traceback

class State:
	
	def __init__(self):
		self.csv_file = 'data.csv'
		self.num_options = 0

state = State()

def get_md5(fname):
	print(f'computing hash ... ', end='')
	hash_md5 = hashlib.md5()
	with open(fname, "rb") as f:
		for chunk in iter(lambda: f.read(4096), b""):
			hash_md5.update(chunk)
	h = hash_md5.hexdigest()
	print(f'{h}')
	return h

def get_entropy(data, offset=0):
	print(f'computing entropy @{offset} ... ', end='')
	if len(data) == 0:
		print(f'len: 0')
		return 0.0
	occurences = array.array('L', [0] * 256)
	for x in data:
		occurences[x if isinstance(x, int) else ord(x)] += 1
	
	entropy = 0
	for x in occurences:
		if x:
			p_x = float(x) / len(data)
			entropy -= p_x * math.log(p_x, 2)
	
	print(f'{entropy:.2f}')
	return entropy

def get_resources(pe):
	"""Extract resources :
	[entropy, size]"""
	print(f'extracting resources ... ')
	resources = []
	if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
		try:
			for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
				if hasattr(resource_type, 'directory'):
					for resource_id in resource_type.directory.entries:
						if hasattr(resource_id, 'directory'):
							for resource_lang in resource_id.directory.entries:
								data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)
								size = resource_lang.data.struct.Size
								entropy = get_entropy(data, resource_lang.data.struct.OffsetToData)
								
								resources.append([entropy, size])
		except Exception as e:
			pass
	print(f'resources: {len(resources)}')
	return resources

def get_version_info(pe):
	"""Return version infos"""
	res = {}
	for fileinfo in pe.FileInfo:
		if fileinfo.Key == 'StringFileInfo':
			for st in fileinfo.StringTable:
				for entry in st.entries.items():
					res[entry[0]] = entry[1]
		if fileinfo.Key == 'VarFileInfo':
			for var in fileinfo.Var:
				res[var.entry.items()[0][0]] = var.entry.items()[0][1]
	if hasattr(pe, 'VS_FIXEDFILEINFO'):
		res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags
		res['os'] = pe.VS_FIXEDFILEINFO.FileOS
		res['type'] = pe.VS_FIXEDFILEINFO.FileType
		res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS
		res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS
		res['signature'] = pe.VS_FIXEDFILEINFO.Signature
		res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion
	return res

def extract_infos(file_path):
	res = []
	res.append(os.path.basename(file_path))
	hash = get_md5(file_path)
	
	print(f'analyzing pe ... ', end='')
	pe = pefile.PE(file_path, fast_load=False)
	print(f'done ', end='')
	
	res.append(pe.FILE_HEADER.Machine)
	res.append(pe.FILE_HEADER.SizeOfOptionalHeader)
	res.append(pe.FILE_HEADER.Characteristics)
	print(f'header ', end='')
	res.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)
	res.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)
	res.append(pe.OPTIONAL_HEADER.SizeOfCode)
	res.append(pe.OPTIONAL_HEADER.SizeOfInitializedData)
	res.append(pe.OPTIONAL_HEADER.SizeOfUninitializedData)
	res.append(pe.OPTIONAL_HEADER.AddressOfEntryPoint)
	res.append(pe.OPTIONAL_HEADER.BaseOfCode)
	
	try:
		res.append(pe.OPTIONAL_HEADER.BaseOfData)
	except AttributeError:
		res.append(0)
	
	res.append(pe.OPTIONAL_HEADER.ImageBase)
	res.append(pe.OPTIONAL_HEADER.SectionAlignment)
	res.append(pe.OPTIONAL_HEADER.FileAlignment)
	res.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)
	res.append(pe.OPTIONAL_HEADER.MinorOperatingSystemVersion)
	res.append(pe.OPTIONAL_HEADER.MajorImageVersion)
	res.append(pe.OPTIONAL_HEADER.MinorImageVersion)
	res.append(pe.OPTIONAL_HEADER.MajorSubsystemVersion)
	res.append(pe.OPTIONAL_HEADER.MinorSubsystemVersion)
	res.append(pe.OPTIONAL_HEADER.SizeOfImage)
	res.append(pe.OPTIONAL_HEADER.SizeOfHeaders)
	res.append(pe.OPTIONAL_HEADER.CheckSum)
	res.append(pe.OPTIONAL_HEADER.Subsystem)
	res.append(pe.OPTIONAL_HEADER.DllCharacteristics)
	res.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)
	res.append(pe.OPTIONAL_HEADER.SizeOfStackCommit)
	res.append(pe.OPTIONAL_HEADER.SizeOfHeapReserve)
	res.append(pe.OPTIONAL_HEADER.SizeOfHeapCommit)
	res.append(pe.OPTIONAL_HEADER.LoaderFlags)
	res.append(pe.OPTIONAL_HEADER.NumberOfRvaAndSizes)
	print(f'optional ', end='')
	res.append(len3(pe.sections))
	entropy = list(map(lambda x: x.get_entropy(), pe.sections))
	print(f'entropy ', end='')
	res.append(sum3(entropy) / float(len3(entropy)))
	res.append(min(entropy))
	res.append(max(entropy))
	raw_sizes = list(map(lambda x: x.SizeOfRawData, pe.sections))
	res.append(sum3(raw_sizes) / float(len3(raw_sizes)))
	res.append(min(raw_sizes))
	res.append(max(raw_sizes))
	print(f'raw ', end='')
	virtual_sizes = list(map(lambda x: x.Misc_VirtualSize, pe.sections))
	res.append(sum3(virtual_sizes) / float(len3(virtual_sizes)))
	res.append(min(virtual_sizes))
	res.append(max(virtual_sizes))
	print(f'virtual ', end='')
	
	# Imports
	try:
		res.append(len3(pe.DIRECTORY_ENTRY_IMPORT))
		imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])
		res.append(len3(imports))
		res.append(len3(filter(lambda x: x.name is None, imports)))
		print(f'imports ', end='')
	except AttributeError:
		res.append(0)
		res.append(0)
		res.append(0)
	# Exports
	try:
		print(f'exports ', end='')
		res.append(len3(pe.DIRECTORY_ENTRY_EXPORT.symbols))
	except AttributeError:
		# No export
		res.append(0)
	
	# Resources
	print(f'\r\nanalyzing resources ...')
	resources = get_resources(pe)
	res.append(len3(resources))
	
	if len3(res):
		entropy = list(map(lambda x: x[0], resources))
		
		if len3(entropy):
			res.append(float(sum3(entropy)) / float(len3(entropy)))
			res.append(min(entropy))
			res.append(max(entropy))
		else:
			res.append(0.0)
			res.append(0)
			res.append(0)
		
		sizes = list(map(lambda x: x[1], resources))
		if len3(sizes):
			res.append(float(sum3(sizes)) / float(len3(sizes)))
			res.append(min(sizes))
			res.append(max(sizes))
		else:
			res.append(0.0)
			res.append(0)
			res.append(0)
	else:
		res.append(0)
		res.append(0)
		res.append(0)
		res.append(0)
		res.append(0)
		res.append(0)
	
	# Load configuration size
	try:
		res.append(pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size)
	except AttributeError:
		res.append(0)
	
	# Version configuration size
	try:
		version_infos = get_version_info(pe)
		res.append(len(version_infos.keys()))
	except AttributeError:
		res.append(0)
	
	if len(res) != state.num_options - 1:
		print(f'error options')
		sys.exit(-1)
	
	return res

if __name__ == '__main__':
	if os.path.exists(state.csv_file):
		shutil.move(state.csv_file, state.csv_file + str(time.gmtime().tm_sec))
	
	csv_delimiter = "|"
	columns = [
		"Name",
		# "MD5",
		"Machine",
		"SizeOfOptionalHeader",
		"Characteristics",
		"MajorLinkerVersion",
		"MinorLinkerVersion",
		"SizeOfCode",
		"SizeOfInitializedData",
		"SizeOfUninitializedData",
		"AddressOfEntryPoint",
		"BaseOfCode",
		"BaseOfData",
		"ImageBase",
		"SectionAlignment",
		"FileAlignment",
		"MajorOperatingSystemVersion",
		"MinorOperatingSystemVersion",
		"MajorImageVersion",
		"MinorImageVersion",
		"MajorSubsystemVersion",
		"MinorSubsystemVersion",
		"SizeOfImage",
		"SizeOfHeaders",
		"CheckSum",
		"Subsystem",
		"DllCharacteristics",
		"SizeOfStackReserve",
		"SizeOfStackCommit",
		"SizeOfHeapReserve",
		"SizeOfHeapCommit",
		"LoaderFlags",
		"NumberOfRvaAndSizes",
		"SectionsNb",
		"SectionsMeanEntropy",
		"SectionsMinEntropy",
		"SectionsMaxEntropy",
		"SectionsMeanRawsize",
		"SectionsMinRawsize",
		"SectionMaxRawsize",
		"SectionsMeanVirtualsize",
		"SectionsMinVirtualsize",
		"SectionMaxVirtualsize",
		"ImportsNbDLL",
		"ImportsNb",
		"ImportsNbOrdinal",
		"ExportNb",
		"ResourcesNb",
		"ResourcesMeanEntropy",
		"ResourcesMinEntropy",
		"ResourcesMaxEntropy",
		"ResourcesMeanSize",
		"ResourcesMinSize",
		"ResourcesMaxSize",
		"LoadConfigurationSize",
		"VersionInformationSize",
		"b_suspicious"
	]
	
	state.num_options = len(columns)
	
	with open(state.csv_file, "at") as data_csv:
		data_csv.write(csv_delimiter.join(columns) + "\r\n")
		
		cur_idx = 0
		mal_dir = os.listdir('malicious')
		total_mals = len(mal_dir)
		done = 0
		for mal_file in mal_dir:
			perc = (done / total_mals) * 100.0
			print(f'{perc:.2f}% analyzing malicious: {mal_file}')
			try:
				print(f'extracting info ...')
				res = extract_infos(os.path.join('malicious/', mal_file))
				res.append(1)
				print(f'saving info ...')
				data_csv.write(csv_delimiter.join(map(lambda x: str(x), res)) + "\n")
			except pefile.PEFormatError:
				print('\t -> Bad PE format')
			except Exception as e:
				print(f'{mal_file}->exception: {type(e)}: {e}')
				traceback.print_exc()
				sys.exit(-1)
			done += 1
		
		# Launch legitimate
		legitimate_dir = os.listdir('legitimate')
		legitimate_dir = legitimate_dir[0:total_mals]
		total_legitimate = len(legitimate_dir)
		done = 0
		for legitimate_file in legitimate_dir:
			cur_idx += 1
			if cur_idx >= total_mals:
				break
			
			perc = (done / total_legitimate) * 100.0
			print(f'{perc:.2f}% analyzing legitimate: {legitimate_file}')
			try:
				print(f'extracting info ...')
				res = extract_infos(os.path.join('legitimate/', legitimate_file))
				res.append(0)
				print(f'saving info ...')
				data_csv.write(csv_delimiter.join(map(lambda x: str(x), res)) + "\n")
			except pefile.PEFormatError:
				print('\t -> Bad PE format')
			except Exception as e:
				print(f'{legitimate_file}->exception: {type(e)}: {e} ')
				traceback.print_exc()
				sys.exit(-1)
			done += 1
